{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfd9738",
   "metadata": {},
   "source": [
    "# AgriSens : SMART CROP RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0594fba-4839-4883-9316-288b69fb26a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mPython was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings > Manage App Execution Aliases. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2810f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ac192",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053947a5",
   "metadata": {},
   "source": [
    "This dataset consists of **2200 rows** in total.\n",
    "\n",
    "**Each row has 8 columns representing Nitrogen, Phosphorous, Potassium, Temperature, Humidity, PH, Rainfall and Label**\n",
    "\n",
    "NPK(Nitrogen, Phosphorous and Potassium) values represent the NPK values in the soil. Temperature, humidity and rainfall are the average values of the sorroundings environment respectively. PH is the PH value present in the soil. **The Label column tells us the type of crop that's best suited to grow based on these conditions.**  \n",
    "**Label is the value we will be predicting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66634077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01286977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cccb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include='number')  # Select numeric columns only\n",
    "sns.heatmap(numeric_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]\n",
    "target = df['label']\n",
    "labels = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e479b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing empty lists to append all model's name and corresponding name\n",
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f2d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24690d0b",
   "metadata": {},
   "source": [
    "# 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DecisionTree = DecisionTreeClassifier(criterion=\"entropy\",random_state=2,max_depth=5)\n",
    "\n",
    "DecisionTree.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = DecisionTree.predict(Xtest)\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Decision Tree')\n",
    "print(\"DecisionTrees's Accuracy is: \", x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d83de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (Decision Tree)\n",
    "score = cross_val_score(DecisionTree, features, target,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bb597",
   "metadata": {},
   "source": [
    "### Saving trained Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "DT_pkl_filename = 'DecisionTree.pkl'\n",
    "# Open the file to save as pkl file\n",
    "DT_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(DecisionTree, DT_Model_pkl)\n",
    "# Close the pickle instances\n",
    "DT_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb67fd3",
   "metadata": {},
   "source": [
    "# 2.Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NaiveBayes = GaussianNB()\n",
    "\n",
    "NaiveBayes.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = NaiveBayes.predict(Xtest)\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Naive Bayes')\n",
    "print(\"Naive Bayes's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (NaiveBayes)\n",
    "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13fc470",
   "metadata": {},
   "source": [
    "### Saving trained Guassian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b96af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "NB_pkl_filename = 'NBClassifier.pkl'\n",
    "# Open the file to save as pkl file\n",
    "NB_Model_pkl = open(NB_pkl_filename, 'wb')\n",
    "pickle.dump(NaiveBayes, NB_Model_pkl)\n",
    "# Close the pickle instances\n",
    "NB_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a183b697",
   "metadata": {},
   "source": [
    "# 3.Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13660750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = SVC(gamma='auto')\n",
    "\n",
    "SVM.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = SVM.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('SVM')\n",
    "print(\"SVM's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac47ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (SVM)\n",
    "score = cross_val_score(SVM,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca30291",
   "metadata": {},
   "source": [
    "# 4.Logistic Refression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aab7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression(random_state=2)\n",
    "\n",
    "LogReg.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = LogReg.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('Logistic Regression')\n",
    "print(\"Logistic Regression's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (Logistic Regression)\n",
    "score = cross_val_score(LogReg,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf5707",
   "metadata": {},
   "source": [
    "### Saving Trained Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "LR_pkl_filename = 'LogisticRegression.pkl'\n",
    "# Open the file to save as pkl file\n",
    "LR_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(LogReg, LR_Model_pkl)\n",
    "# Close the pickle instances\n",
    "LR_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b27f5df",
   "metadata": {},
   "source": [
    "# 5.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b46acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=20, random_state=5)\n",
    "RF.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = RF.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('RF')\n",
    "print(\"RF's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (Random Forest)\n",
    "score = cross_val_score(RF,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82d743",
   "metadata": {},
   "source": [
    "### Saving Trained Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fedad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "RF_pkl_filename = 'RandomForest.pkl'\n",
    "# Open the file to save as pkl file\n",
    "RF_Model_pkl = open(RF_pkl_filename, 'wb')\n",
    "pickle.dump(RF, RF_Model_pkl)\n",
    "# Close the pickle instances\n",
    "RF_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabaa150",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Open the file to save as pkl file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m RF_Model_pkl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(RF_pkl_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mRF\u001b[49m, RF_Model_pkl)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Close the pickle instances\u001b[39;00m\n\u001b[0;32m      8\u001b[0m RF_Model_pkl\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RF' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "RF_pkl_filename = 'RF.pkl'\n",
    "# Open the file to save as pkl file\n",
    "RF_Model_pkl = open(RF_pkl_filename, 'wb')\n",
    "pickle.dump(RF, RF_Model_pkl)\n",
    "# Close the pickle instances\n",
    "RF_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba6257",
   "metadata": {},
   "source": [
    "# 6.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05326d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming Ytrain is your target variable\n",
    "label_encoder = LabelEncoder()\n",
    "Ytrain_encoded = label_encoder.fit_transform(Ytrain)\n",
    "\n",
    "XB = xgb.XGBClassifier()\n",
    "XB.fit(Xtrain, Ytrain_encoded)\n",
    "\n",
    "# Assuming Ytest is your test set target variable\n",
    "Ytest_encoded = label_encoder.transform(Ytest)\n",
    "\n",
    "predicted_values = XB.predict(Xtest)\n",
    "\n",
    "x = accuracy_score(Ytest_encoded, predicted_values)\n",
    "acc.append(x)\n",
    "model.append('XGBoost')\n",
    "print(\"XGBoost's Accuracy is: \", x)\n",
    "\n",
    "print(classification_report(Ytest_encoded, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming target is your target variable\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(target)\n",
    "\n",
    "XB = xgb.XGBClassifier()\n",
    "\n",
    "# Use StratifiedKFold to maintain class distribution during cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation score (XGBoost)\n",
    "score = cross_val_score(XB, features, target_encoded, cv=cv)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4347e8d",
   "metadata": {},
   "source": [
    "### Saving Trained XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "XB_pkl_filename = 'XGBoost.pkl'\n",
    "# Open the file to save as pkl file\n",
    "XB_Model_pkl = open(XB_pkl_filename, 'wb')\n",
    "pickle.dump(XB, XB_Model_pkl)\n",
    "# Close the pickle instances\n",
    "XB_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdba585",
   "metadata": {},
   "source": [
    "# 7. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train the KNN classifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  \n",
    "classifier.fit(Xtrain, Ytrain)  \n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(Xtest) \n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Ytest, y_pred)\n",
    "acc.append(accuracy)\n",
    "model.append('KNN')\n",
    "print(\"KNN classifier's Accuracy is:\", accuracy) \n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(Ytest, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f50e7d1",
   "metadata": {},
   "source": [
    "### Saving trained KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ccb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the filename for saving the KNeighborsClassifier model\n",
    "KNN_pkl_filename = 'KNeighborsClassifier.pkl'\n",
    "\n",
    "# Open the file to save the KNeighborsClassifier model as a pkl file\n",
    "with open(KNN_pkl_filename, 'wb') as KNN_Model_pkl:\n",
    "    # Dump the trained KNeighborsClassifier object into the pkl file\n",
    "    pickle.dump(classifier, KNN_Model_pkl)\n",
    "\n",
    "# No need to close the pickle file explicitly as we are using 'with' statement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41298d4",
   "metadata": {},
   "source": [
    "# ACCURACY COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5],dpi = 100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Algorithm')\n",
    "sns.barplot(x = acc,y = model,palette='dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5], dpi=100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy')\n",
    "sns.barplot(x=model, y=acc, palette='dark')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 5], dpi=100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Algorithm')\n",
    "plt.ylabel('Accuracy')\n",
    "sns.barplot(x=model, y=acc, palette='dark')\n",
    "\n",
    "# Add accuracy percentages above each bar\n",
    "for i, accuracy in enumerate(acc):\n",
    "    plt.text(i, accuracy + 0.01, f'{accuracy:.2%}', ha='center')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea58a8",
   "metadata": {},
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c507421",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd44627",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[104,18, 30, 23.603016, 60.3, 6.7, 140.91]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ae483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[101,11, 36, 23.603016, 60.3, 6.1, 140.91]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a732eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f674d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print('\\nMissing values in each column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print('\\nNumber of duplicate rows:', df.duplicated().sum())\n",
    "\n",
    "# Check the data types of each column\n",
    "print('\\nData types of each column:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dac505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print('Training set:', X_train.shape, y_train.shape)\n",
    "print('Testing set:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7f657",
   "metadata": {},
   "source": [
    "# Accuracy of Random Forest Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "RF_model = RandomForestClassifier(n_estimators=20, random_state=5)\n",
    "RF_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = RF_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the RandomForest model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of RandomForest Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "#plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for better visualization\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443a1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "RF_model = RandomForestClassifier(n_estimators=20, random_state=5)\n",
    "RF_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = RF_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the RandomForest model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='blue', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of RandomForest Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "#plt.ylim(0, 1)  # Set y-axis limit from 0 to 1 for better visualization\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bb58ff",
   "metadata": {},
   "source": [
    "# Accuracy of Decision Tree Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e346dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "DT_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=2, max_depth=5)\n",
    "DT_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = DT_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Decision Tree model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='green', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Decision Tree Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1743f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "DT_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=2, max_depth=5)\n",
    "DT_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = DT_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Decision Tree model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Decision Tree Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae3535e",
   "metadata": {},
   "source": [
    "# Accuracy of Naive Bayes Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = NB_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Naive Bayes model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='orange', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Naive Bayes Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = NB_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Naive Bayes model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Naive Bayes Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c900a98",
   "metadata": {},
   "source": [
    "# Accuracy of SVM Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "SVM_model = SVC(gamma='auto')\n",
    "SVM_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = SVM_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the SVM model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='purple', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of SVM Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9038385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "SVM_model = SVC(gamma='auto')\n",
    "SVM_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = SVM_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the SVM model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of SVM Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66273487",
   "metadata": {},
   "source": [
    "# Accuracy of Logistic Regression Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "LR_model = LogisticRegression(random_state=2)\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = LR_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Logistic Regression model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='red', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Logistic Regression Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e5f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "LR_model = LogisticRegression(random_state=2)\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = LR_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the Logistic Regression model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of Logistic Regression Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd092f4",
   "metadata": {},
   "source": [
    "# Accuracy of KNN Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dae08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = KNN_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the KNN model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='brown', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of KNN Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = KNN_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the KNN model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of KNN Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabe8a1",
   "metadata": {},
   "source": [
    "# Accuracy of XGBoost Model for each crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0150149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "XGB_model = xgb.XGBClassifier()\n",
    "XGB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = XGB_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the XGBoost model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(crop_labels, accuracy_per_crop, marker='o', color='cyan', linestyle='-')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of XGBoost Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "XGB_model = xgb.XGBClassifier()\n",
    "XGB_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop labels for the testing set\n",
    "predicted_labels = XGB_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy for each crop\n",
    "accuracy_per_crop = []\n",
    "crop_labels = le.inverse_transform(sorted(np.unique(y_test)))  # Get sorted unique crop labels\n",
    "for crop_label in crop_labels:\n",
    "    indices = (y_test == le.transform([crop_label])[0])  # Indices for current crop label\n",
    "    accuracy = accuracy_score(y_test[indices], predicted_labels[indices])\n",
    "    accuracy_per_crop.append(accuracy)\n",
    "\n",
    "# Plot the accuracy of the XGBoost model for each crop\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=crop_labels, y=accuracy_per_crop, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Accuracy of XGBoost Model for Each Crop')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Crop')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e233129",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 7, 3, 50, 39.90, 3, 70.2]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfacc779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
